{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from TextHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_Set_1_credible: articles    4394\n",
      "dtype: int64\n",
      "data_Set_2_credible: articles    1211\n",
      "dtype: int64\n",
      "data_Set_3_not-credible: articles    2704\n",
      "dtype: int64\n",
      "data_Set_4_not-credible: articles    3381\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sources = pd.read_json('datasets/sources.json', orient='index')\n",
    "\n",
    "df_credible_1 = pd.read_json('datasets/source_3/scraped_articles.json')\n",
    "df_credible_2 = pd.read_json('datasets/source_6/scraped_articles.json')\n",
    "\n",
    "df_not_credible_1 = pd.read_json('datasets/source_7/scraped_articles.json')\n",
    "df_not_credible_2 = pd.read_json('datasets/source_14/scraped_articles.json')\n",
    "\n",
    "print(\"data_Set_1_credible:\",df_credible_1.count())\n",
    "print(\"data_Set_2_credible:\",df_credible_2.count())\n",
    "print(\"data_Set_3_not-credible:\",df_not_credible_1.count())\n",
    "print(\"data_Set_4_not-credible:\",df_not_credible_2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_Set_3_credible: articles    2288\n",
      "dtype: int64\n",
      "data_Set_3_not-credible: articles    3654\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_credible_3 = pd.read_json('datasets/source_1/scraped_articles.json')\n",
    "\n",
    "df_not_credible_3 = pd.read_json('datasets/source_8/scraped_articles.json')\n",
    "\n",
    "print(\"data_Set_3_credible:\",df_credible_3.count())\n",
    "print(\"data_Set_3_not-credible:\",df_not_credible_3.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame:\n",
      "                                                text  credibility\n",
      "0  تمكنت عناصر جهاز خفر السواحل الليبي، فجر اليوم...            1\n",
      "1  أكد المبعوث الأميركي الخاص إلى السودان وجنوب ا...            1\n",
      "2  ‬اطلع رئيس لجنة الإدارة المكلف بشركة الخليج ال...            1\n",
      "3  ‬نشرت الشركة الليبية للموانئ بيانات حديثة أظهر...            1\n",
      "4  طالب حراك “الاستفتاء أولا” بعرض مسودة الدستور ...            1\n"
     ]
    }
   ],
   "source": [
    "df_credible_1['credibility'] = 1\n",
    "df_credible_2['credibility'] = 1\n",
    "df_not_credible_1['credibility'] = 0\n",
    "df_not_credible_2['credibility'] = 0\n",
    "df_credible_3['credibility'] = 1\n",
    "df_not_credible_3['credibility'] = 0\n",
    "\n",
    "merged_df = pd.concat([df_credible_1, df_credible_2, df_not_credible_1, df_not_credible_2,df_credible_3, df_not_credible_3])\n",
    "\n",
    "# merged_df['credibility'] = 1\n",
    "# merged_df.loc[merged_df.index.isin(df_not_credible_1.index) | merged_df.index.isin(df_not_credible_2.index), 'credibility'] = 0\n",
    "\n",
    "\n",
    "texts = []\n",
    "for article in merged_df['articles']:\n",
    "    text = article['text']\n",
    "    texts.append(text)\n",
    "\n",
    "merged_df['text'] = texts\n",
    "\n",
    "new_df = merged_df[['text', 'credibility']]\n",
    "print(\"New DataFrame:\")\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_credible_3['credibility'] = 1\n",
    "# df_not_credible_3['credibility'] = 0\n",
    "\n",
    "# merged_df_test = pd.concat([df_credible_3, df_not_credible_3])\n",
    "\n",
    "# print(merged_df_test['credibility'].value_counts()[1])\n",
    "\n",
    "# texts = []\n",
    "# for article in merged_df_test['articles']:\n",
    "#     text = article['text']\n",
    "#     texts.append(text)\n",
    "\n",
    "# merged_df_test['text'] = texts\n",
    "\n",
    "# new_df_test = merged_df_test[['text', 'credibility']]\n",
    "# print(\"New DataFrame:\")\n",
    "# print(new_df_test.head())\n",
    "\n",
    "# data_test=new_df_test['text']\n",
    "# preprocessed_data_test=preprocess_text(data_test)\n",
    "# print(preprocessed_data_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تمك عنصر جهز خفر سحل ليب فجر اليوم قاذ هجر طرق الا شواطاء الا ورب علا متن زورق ططي نقل وكل ليب نطق رئس ارك قوت بحر ان زورق زوي تحر تلق ندء غاث عمل علا قاذ هجر زال قعد طرابلس بحر نقل الا جهز كفح هجر قنن تمم جرء رحل بلد وكان خفر سحل ليب اعد ايم قلل هجر الا ليب خلل عمل قاذ نفذ طلع اعل تحدث بسم ظمه هجر دول\n"
     ]
    }
   ],
   "source": [
    "data=new_df['text']\n",
    "preprocessed_data=preprocess_text(data)\n",
    "print(preprocessed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, new_df['credibility'], test_size=0.2, random_state=42)\n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3), (4, 4)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    RandomForestClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "metrics_dict = {}\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    ngram_metrics = {}\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    X_train_normalized = preprocessing.normalize(X_train_tfidf, norm='l2')\n",
    "    X_test_normalized = preprocessing.normalize(X_test_tfidf, norm='l2')\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "        classifier_metrics = []\n",
    "\n",
    "        classifier.fit(X_train_normalized, y_train)\n",
    "        y_pred = classifier.predict(X_test_normalized)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        classifier_metrics.extend([accuracy, precision, recall, f1])\n",
    "        ngram_metrics[classifier_name] = classifier_metrics\n",
    "\n",
    "    metrics_dict[ngram_range] = ngram_metrics\n",
    "\n",
    "for ngram_range, ngram_metrics in metrics_dict.items():\n",
    "    print(f\"n-gram range {ngram_range}:\")\n",
    "    for classifier_name, classifier_metrics in ngram_metrics.items():\n",
    "        print(f\"{classifier_name}: {classifier_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Accuracy for n-gram range (1, 1): 0.8463283243549758\n",
      "Accuracy for n-gram range (2, 2): 0.856818826197902\n",
      "Accuracy for n-gram range (3, 3): 0.8432095265097816\n",
      "Accuracy for n-gram range (4, 4): 0.7924581797561667\n",
      "Classifier: MultinomialNB\n",
      "Accuracy for n-gram range (1, 1): 0.7734618656081655\n",
      "Accuracy for n-gram range (2, 2): 0.8250637935922881\n",
      "Accuracy for n-gram range (3, 3): 0.8281825914374823\n",
      "Accuracy for n-gram range (4, 4): 0.7862205840657783\n",
      "Classifier: RandomForestClassifier\n",
      "Accuracy for n-gram range (1, 1): 0.8420754182024384\n",
      "Accuracy for n-gram range (2, 2): 0.8449106889707967\n",
      "Accuracy for n-gram range (3, 3): 0.7785653529912107\n",
      "Accuracy for n-gram range (4, 4): 0.7142047065494754\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy for n-gram range (1, 1): 0.8219449957470939\n",
      "Accuracy for n-gram range (2, 2): 0.8287496455911539\n",
      "Accuracy for n-gram range (3, 3): 0.830450808052169\n",
      "Accuracy for n-gram range (4, 4): 0.8015310462149136\n",
      "Classifier: SVC\n",
      "Accuracy for n-gram range (1, 1): 0.8704281258860221\n",
      "Accuracy for n-gram range (2, 2): 0.856818826197902\n",
      "Accuracy for n-gram range (3, 3): 0.8261979018996314\n",
      "Accuracy for n-gram range (4, 4): 0.7507796994612985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, new_df['credibility'], test_size=0.2, random_state=42)\n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3), (4, 4)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    RandomForestClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    print(f\"Classifier: {classifier_name}\")\n",
    "    for ngram_range in ngram_ranges:\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "        Cv_train = vectorizer.fit_transform(X_train)\n",
    "        Cv_test = vectorizer.transform(X_test)\n",
    "\n",
    "        X_train_normalized = preprocessing.normalize(Cv_train, norm='l2')\n",
    "        X_test_normalized = preprocessing.normalize(Cv_test, norm='l2')\n",
    "\n",
    "        classifier.fit(X_train_normalized, y_train)\n",
    "        y_pred = classifier.predict(X_test_normalized)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy for n-gram range {ngram_range}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Accuracy for n-gram range (1, 1): 0.7621369128613382\n",
      "Accuracy for n-gram range (2, 2): 0.8365473799798362\n",
      "Accuracy for n-gram range (3, 3): 0.8291745502364789\n",
      "Accuracy for n-gram range (4, 4): 0.8044464379076505\n",
      "Classifier: MultinomialNB\n",
      "Accuracy for n-gram range (1, 1): 0.7608889434250103\n",
      "Accuracy for n-gram range (2, 2): 0.7746143878975269\n",
      "Accuracy for n-gram range (3, 3): 0.8035957119384198\n",
      "Accuracy for n-gram range (4, 4): 0.7923094365948704\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy for n-gram range (1, 1): 0.6049783848798854\n",
      "Accuracy for n-gram range (2, 2): 0.5435605500779096\n",
      "Accuracy for n-gram range (3, 3): 0.542142721708766\n",
      "Accuracy for n-gram range (4, 4): 0.4875274139162423\n",
      "Classifier: SVC\n",
      "Accuracy for n-gram range (1, 1): 0.8025747571485251\n",
      "Accuracy for n-gram range (2, 2): 0.6317479243260925\n",
      "Accuracy for n-gram range (3, 3): 0.5900057429108984\n",
      "Accuracy for n-gram range (4, 4): 0.5858657007983628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessed_data\n",
    "y = np.array(new_df['credibility']) \n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3), (4, 4)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=5000), \n",
    "    MultinomialNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    print(f\"Classifier: {classifier_name}\")\n",
    "    for ngram_range in ngram_ranges:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
    "        X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "        accuracies = []\n",
    "        for train_index, test_index in kf.split(X_tfidf):\n",
    "            X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "            X_train_normalized = scaler.fit_transform(X_train)\n",
    "            X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "            classifier.fit(X_train_normalized, y_train)\n",
    "            y_pred = classifier.predict(X_test_normalized)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        print(f\"Accuracy for n-gram range {ngram_range}: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression\n",
      "Accuracy for n-gram range (1, 1): 0.7626468434655532\n",
      "Accuracy for n-gram range (2, 2): 0.8269053847790506\n",
      "Accuracy for n-gram range (3, 3): 0.8223119405747832\n",
      "Accuracy for n-gram range (4, 4): 0.7990583298663048\n",
      "Classifier: MultinomialNB\n",
      "Accuracy for n-gram range (1, 1): 0.7637814181532271\n",
      "Accuracy for n-gram range (2, 2): 0.805523937292109\n",
      "Accuracy for n-gram range (3, 3): 0.8150521517743119\n",
      "Accuracy for n-gram range (4, 4): 0.794804796512633\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy for n-gram range (1, 1): 0.6515426816000577\n",
      "Accuracy for n-gram range (2, 2): 0.5353922845576166\n",
      "Accuracy for n-gram range (3, 3): 0.5654486474246719\n",
      "Accuracy for n-gram range (4, 4): 0.5652217453528013\n",
      "Classifier: SVC\n",
      "Accuracy for n-gram range (1, 1): 0.8165834070562701\n",
      "Accuracy for n-gram range (2, 2): 0.6311241969212144\n",
      "Accuracy for n-gram range (3, 3): 0.5855253557315971\n",
      "Accuracy for n-gram range (4, 4): 0.582179285926684\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessed_data\n",
    "y = np.array(new_df['credibility']) \n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3), (4, 4)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=5000), \n",
    "    MultinomialNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    print(f\"Classifier: {classifier_name}\")\n",
    "    for ngram_range in ngram_ranges:\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "        X_cv = vectorizer.fit_transform(X)\n",
    "\n",
    "        accuracies = []\n",
    "        for train_index, test_index in kf.split(X_cv):\n",
    "            X_train, X_test = X_cv[train_index], X_cv[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "            X_train_normalized = scaler.fit_transform(X_train)\n",
    "            X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "            classifier.fit(X_train_normalized, y_train)\n",
    "            y_pred = classifier.predict(X_test_normalized)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        print(f\"Accuracy for n-gram range {ngram_range}: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Check if a GPU is available and set the device accordingly\n",
    "device = tf.device(\"cuda:0\" if tf.test.is_gpu_available() else \"cpu\")\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU\")\n",
    "else:\n",
    "    print(\"CPU\")\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, new_df['credibility'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences of indices\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure equal length\n",
    "max_sequence_length = max(len(seq) for seq in X_train_sequences)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Create the RNN model with LSTM cells\n",
    "with device:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_padded, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict_classes(X_test_padded)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)\n",
    "#Number of accuracies\n",
    "print(len(accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
